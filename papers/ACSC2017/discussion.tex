\section{Discussion}

One of the reasons refactoring is not a straightforward topic is because of the different ways people might interpret a refactoring. In some domains or context, a perceivable behaviour violating change may not even matter. There are some cases where garnering user feedback will offer a clear-cut decision, but there are likely cases that will not. Caring is important because even if a user dislikes the way code is pretty-printed, for instance, they might avoid a tool entirely. Offering choice sounds good, but deciding what is an error, or a warning is still not easy (with better granularity here being a goal). One recent example that has come to light is the existence of conditional compilation within Rust. If performing a refactoring breaks other platforms, but not yours, should that be a problem? In particular, you may not have the required analysis of the remaining code, in which case a failure might be better.

As raised throughout this report, lack of formalism is an ongoing problem in the area of refactoring. General progress in the field of refactoring appears quite slow, with many opting to simply produce implementations rather than tackling the problem at large. In terms of missing formalisms, refactoring is not the only one at blame it appears. Much in the same way, compilers encode otherwise undescribed aspects of programming languages. Rust is no different, and the case with the relatively informal elision RFC (which was descriptive but definitely not complete) was a reminder of this. Being well-defined likely would have allowed reversal of the elision rules with much more ease. This is not a reason to point blame, but to highlight the genuine scale and complexity of the projects and issues at hand. 

Given the current architecture of the tool, there are a number of further improvements that could be made to the compiler to improve its efficacy and efficiency. Using {\verb|-Zsave| \verb|-analysis|} provides another additional step before a refactoring can be made. Furthermore, it must be generated every time a refactoring is to be undergone. By providing a library and API with which this information can be queried using the existing compiler API, the need for csv parsing and associated unrelated complexity disappears. The actual performance offset of having to run the compiler again to generate this information does not disappear however.  

Helping to address performance in the compiler itself in the general case should also help to improve performance of the refactoring tool. However, based on the current design of the tool and the need for multiple runs with modified source, the issue of performance would be better addressed by improvements to the name resolution module in the Rust compiler. In particular, providing name resolution for usages instead of just at the declaration level would turn O(N) runs of the compiler into O(1) by using name resolution multiple times in a single run. Fundamentally this requires heavy changes to the structure of the compiler and the nature of name resolution. As it currently is, not every node gets its individual node id in nested expressions and to resolve this requires significantly more memory usage or novel, significant and well-architected changes, well beyond the scope of this project.

Currently macros are completely ignored by the save-analysis report generated by the compiler. As it is, this appears to be a major shortcoming in the refactoring tool that has yet to be addressed. However, not a lot can be done at this point due to the general limitations regarding macros and how they are typically ignored when generating metadata from the compiler. Without being able to identify any spans associated with macros, it isn't possible to make the necessary code transformations. Implementing the necessary functionality is certainly non-trivial and likely requires much better domain knowledge than that which could be provided here. Resolving this would also fix pretty printer abstraction layer issues.

The relationship between macro hygiene and refactoring is particularly novel, but from initial analysis, does not appear to provide any particular benefits. Further research into the relationship might provide some unique insights and a system which is able to incorporate both would be of significant academic interest, and interest to this author.

Efficiency of large-scale refactoring in general needs more attention. Although analysis of individual packages on a service like Crates.io provides some benefits, it would be curious to see how a tool functions on code bases which are much larger, in the order of hundreds of thousands of lines of code or larger. Although the expectations on this particular tool are not quite so high, understanding the general tradeoffs of provably correct refactorings and time taken and developer perception of this tradeoff is likely to produce fascinating observations. Looking at the Google-scale of refactoring, Google have set up a Clang map-reduce to perform refactoring on large codebases over a network of machines \cite{carruth2011clang}. Evidently the utility and associated confidence in such refactorings led them to spend the time to create such a framework, but determining when this happens in the general case provides provocative food-for-thought.